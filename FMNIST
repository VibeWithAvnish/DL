import tensorflow as tf
from tensorflow.keras import models, layers
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.optimizers import Adam

# Load the training and testing data
train_data = pd.read_csv(r"C:\Avnish\desktop_new\Sem 7\z_DL_Dataset\fashion-mnist_train.csv\fashion-mnist_train.csv")
test_data = pd.read_csv(r"C:\Avnish\desktop_new\Sem 7\z_DL_Dataset\fashion-mnist_test.csv\fashion-mnist_test.csv")

# Prepare the data
X_train = train_data.iloc[:, 1:].values  # Get pixel values
y_train = train_data.iloc[:, 0].values    # Get labels
X_test = test_data.iloc[:, 1:].values     # Get pixel values
y_test = test_data.iloc[:, 0].values      # Get labels

# Normalize the data
X_train = X_train / 255.0
X_test = X_test / 255.0

# Reshape the data to match the model input
X_train = X_train.reshape(-1, 28, 28, 1)
X_test = X_test.reshape(-1, 28, 28, 1)

# Define the model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.0001),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(X_train, y_train, epochs=30, validation_split=0.2)

# Plot training history
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(loc='upper left')
plt.show()

# Evaluate the model on the test data
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print(f'Test accuracy: {test_accuracy:.4f}')

# Predictions and classification report
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)

# Classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred_classes))
# Predictions and classification report
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)

# Display a few test images with true and predicted labels
num_images = 5
random_indices = np.random.choice(X_test.shape[0], num_images, replace=False)

plt.figure(figsize=(10, 2))  # Set up the figure size for better display
for i, idx in enumerate(random_indices):
    test_image = X_test[idx]
    true_label = y_test[idx]  # Use the true label directly

    # Predict the label for the test image
    predicted_label = np.argmax(model.predict(test_image.reshape(1, 28, 28, 1)))

    # Plot the image and prediction
    plt.subplot(1, num_images, i + 1)
    #plt.imshow(test_image.reshape(28, 28), cmap='gray')  # Reshape for correct display
    plt.imshow(test_image, cmap='gray')
    plt.title(f"True: {true_label}\nPred: {predicted_label}")
    plt.axis('off')

plt.tight_layout()
plt.show()

